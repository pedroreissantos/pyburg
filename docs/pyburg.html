<html>
<head>
<title>pyburg (Bottom-Up Rewrite Grammar in python)</title>
</head>
<BODY BGCOLOR="B5BDD6" link=red vlink=green>

<h1>pyburg (Bottom-Up Rewrite Grammar in python)</h1>

<b>
Pedro Reis dos Santos<br>
University of Lisboa<br>
(C)IST, 2020<br>
</b>

<p>
<b>pyburg-1.0</b>
<p>

<div class="sectiontoc">
<ul>
<li><a href="#intro">Introduction</a></li>
<li><a href="#over">Overview</a></li>
<li><a href="#rule">Patterns and costs</a></li>
<li><a href="#cost">Variable costs</a></li>
<li><a href="#postfix">Code generation</a></li>
<li><a href="#example">Examples</a></li>
</ul>

<H2><a name="intro"></a>1. Introduction</H2>
pyburg is a pure-Python implementation of 
<a href="https://github.com/pedroreissantos/pburg">pburg</a>
compiler construction tool, an instruction selector.
The tools scans an abstract syntax tree (AST) for patterns
that correspond to target processor instructions.
If the processor provides alternatives for certain operations,
the tool will select the sequence with a minimal global cost.
The cost can be represented as the instruction latency,
for performance minimization, or any other metric.
The tool scans the AST twice, first labeling the alternative costs on
each tree node for all possible pattern combinations,
then a reduction generates the minimal cost alternative.
<p>
The rest of this document assumes that you are somewhat familiar with
compiler theory, and the use of compiler
construction tools such as lex and yacc.
The specifics of instruction selection are available on the compiler literature, such as:
<ul>
<li>Engineering a compiler, Cooper and Torczon, 2nd Ed, 2011, Morgan kaufmann, 978-0120884780, chapter 11<!-- https://www.amazon.com/Engineering-Compiler-Keith-Cooper/dp/012088478X/-->
</li><li>Modern compiler implementation in C, Appel, 2004, Cambridge university press, 978-0521607650, chapter 9<!-- https://www.amazon.com/Modern-Compiler-Implement-Andrew-Appel/dp/0521607655/ -->
</li><li>Modern compiler design, Grune <i>et al.</i>, 2nd Ed, 2012, Springer, 978-1461446989, section 9.1.4<!--https://www.amazon.com/Modern-Compiler-Design-Dick-Grune/dp/1461446988/ -->
</ul>
<p>
The <b>pyburg</b> tool uses the same structures as <b>ply</b>, where a
set of routines decribe the actions for the grammar.
The grammar itself is embeded in the docstrings of each routine.
The input AST is at most a binary tree with each node labeled with the
grammar terminal symbols.
The AST can be build using <b>ply.yacc</b> or any other tool.
<p>

<H2><a name="over"></a>2. Overview</H2>

The package can be installed using the
<tt>python -m pip pyburg</tt> command (or just <tt>pip install pyburg</tt>).
<p>
Pyburg consists of separate modules: <tt>pyburg.py</tt>,  <tt>Tree.py</tt>, <tt>brg2py.py</tt> and
<tt>postfix.py</tt>, all of which are found in a Python package called <tt>pyburg</tt>.
The <tt>pyburg.py</tt> module is used to select instructions from an AST from a pattern grammar;
The <tt>Tree.py</tt> module is used to represent an abstract syntax tree; other AST representations can be used with pyburg, but each node must be a class instance so that pyburg can attributes with setattr and provide label(), left(), right(), value() and text() methods, depending on the node type;
The <tt>brg2py.py</tt> module is used to convert code.brg files into code.py equivalents;
The <tt>postfix.py</tt> module is used to provide final machine code instrutions for selected instructions;
The <tt>strbuf.py</tt> module is used to collect the code generation into a string instead of writing to a file object.

<p>
Pyburg doesn't involve a separate code-generation process.
Instead, pyburg relies on reflection (introspection) to build the code selector.
The specification given to pburg <em>is</em> valid a Python program.
This means that there are no extra source files nor is there a compiler construction step.

<H2><a name="rule"></a>3. Patterns and costs</H2>

A bottom-up rewrite grammar (BURG) is a context free grammar that describes the abilities of the target processor using a set of tree patterns to be matched with an actual abstract syntax tree (AST).
The parsing of a target language example should produce an AST that can be scanned for tree patterns.
If all nodes in the AST are matched by at least one pattern, the AST can be selected and the output assembler associated with each matched pattern generated.
<p>
The grammar for a trivial language that only performs aditions on literal integers can be described by:
<pre>
expr : INT
expr : ADD(expr,expr)
</pre>
In this grammar all leaf nodes must be integer literals, nodes labeled <tt>INT</tt> and all branches are <tt>ADD</tt> labeled nodes with two branches.
The <tt>expr</tt> non-terminal on the left hand side of each rule can be produced if the tree pattern on right and side matches the AST tree node being analysed.
<p>
Using a stack based processor, final code can be generated without any register allocation.
The first rule pushes the immediate value to the stack: <tt>push dword imm</tt> for <b>intel i386</b> assembler format.
The second rule must pop the arguments and push the added result: <tt>pop eax; add dword [esp], eax</tt>.
Ignoring the latencies of each machine instruction we can use the number of machine instructions as the cost: <b>1</b> for the <tt>push</tt> in the first rule and <b>2</b> for the <tt>pop</tt> and </tt>add</tt> of the second rule.
The costs are added after the pattern on the right hand side:
<pre>
expr : INT 1
expr : ADD(expr,expr) 2
</pre>
<p>
<b>pyburg</b> supports two input formats. In the format the grammar is a dictionary that maps rules into code:
<pre>
gram = {
" expr : INT 1 " : lambda n,u,o: print("push dword", n.value()) ,
" expr : ADD(expr,expr) 2 " : lambda n,u,o: print("pop eax\nadd dword [esp], eax"),
"terminals" : ('INT','ADD'),
"goal": "expr"
}
</pre>
The other uses reflection to process valid python code and extract grammar rules from function docstrings as in <a href="https://github.com/dabeaz/ply">ply</a>:
<pre>
def b_lit(node, user, out) :
    " expr : INT 1 "
		print("push dword", node.value())

def b_add(node, user, out) :
    " expr : ADD(expr,expr) 2 "
    print("pop eax\nadd dword [esp], eax")

terminals = ('INT','ADD')
goal = "expr"
</pre>
The functions, in both formats, are called when the node matches the respective rule pattern.
This first argument is the AST <tt>node</tt> that matched the rule.
The other arguments are supplied by the user and can be used to provide context to the functions, such as a file to print to.
<p>
If only one AST tree node is matched by each rule, only the node label must match the respective grammar terminal symbol (<tt>INT</tt> or <tt>ADD</tt>), and the code selection tool behaves like a visitor pattern.
But the compiler can perform constant-folding optimization by adding the two constants at compile time and generating the result as an immediate value:
<pre>
expr : ADD(INT,INT) 1
</pre>
The resulting function is:
<pre>
def b_fold(node, user, out) :
    " expr : ADD(INT,INT) 1 "
		print("push dword", node.left().value() + node.right().value())
</pre>

Note that the each terminal symbol can only be used with the same arity, i. e. the <tt>INT</tt> is leaf node (no branches), while the <tt>ADD</tt> must always take two branches (arity=2). Inconsistent arity will result in a grammar processing error.
<p>
Missing costs are assumed 0 (zero) and should be avoided if code is generated, since a no cost code can be emited repetedly by the tool.

<H2><a name="cost"></a>6. Variable costs</H2>

The true power of a selection tool can be unleashed when the target processor provides machine instruction that match more than one node.
For instance, if we add variables to our trivial language, the grammar can become:
<pre>
expr : INT
expr : ADD(expr,expr)
expr : ID
expr : ASSIGN(ID,expr)
</pre>
For most processors each rule match a single machine instruction, but we can provide speed-ups for assigning literals i(<b>x=1</b>) and incrementing variables (<b>x=x+1</b>) without changing the language or the tree construction.
<pre>
expr : ASSIGN(ID,INT)
expr : ASSIGN(ID,ADD(ID,INT))
</pre>
The second rule only is an increment if both <tt>ID</tt>s in the pattern match the same variable.
This requires not only a tree pattern match but also matching <tt>ID</tt>s.
This is done through a user defined matching function:
<pre>
def sameVar(p) :
    return 1 if p.left().text() == p.right().left().text() else 1000
</pre>
The function is called only for matching tree patterns, so the left node is
always an <tt>ID</tt> and the other <tt>ID</tt> is on the left of the right
node, and the <tt>strcmp</tt> compares both <tt>ID</tt>s.
The return value is the instruction's cost if the <tt>ID</tt>s match or a
very high value (<tt>1000</tt> for instance) if there is no match.
The high value makes the alternative rules less costly, converting the
<tt>ID</tt>s and the <tt>INT</tt> to <tt>expr</tt> and performing a regular
<tt>ADD</tt> and <tt>ASSIGN</tt>, with a total cost of <tt>5</tt> (one for
each pattern match.
Please note that the function is called to determine the cost during the
labeling process, not during the reduction process, an may be called
multiple times, whenever the pattern is matched.
The cost function must be in the same module, or refered by its full path,
and can only depend on information available at the start of the labeling
process.
Since the function returns the cost, it is placed in the grammar after the
pattern:
<pre>
expr : ASSIGN(ID,ADD(ID,INT)) sameVar
</pre>

The same principle can be applyed to distinguish expressions of different
data types:
<pre>
intexpr : ID isInteger
strexpr : ID isString
realexpr : ID isReal
</pre>
based on type information included in the tree nodes or a symbol table.
Then, <tt>ADD</tt> operations, for instance, can be distinguished based on
grammar non-terminals:
<pre>
intexpr : ADD(intexpr,intexpr) 1
strexpr : ADD(strexpr,strexpr) 30
realexpr : ADD(realexpr,realexpr) 7
</pre>

<H2><a name="postfix"></a>7. Code generation</H2>

The code generation can produce a list of instructions on virtual registers,
for posterior register assignment.
However, if performance is not critical, a small number of registers can be
previously assigned and final machine code generated directly:
see <a href="../exs/sample2.py">sample2</a> example.
<p>
A sistematic approach can use a small number of registers and the stack,
using the processor as a stack machine. 
This approach has a small performance penalization in modern processore
since most of the stack will be acessible in primary cache.
The <a href="postfix.html">postfix</a> macros provide macros for such code
generation for <b>intel</b> (<tt>32</tt> and <tt>64</tt> bit architectures
in <i>intel</i> and <i>AT&amp;T</i> assembler formats) as well as <b>arm</b>
<tt>32</tt> bit.

<H2><a name="example"></a>8. Examples</H2>

The <a href="internals.html">internals</a> of the <b>pyburg</b> describes the
available access functions while the <a href="tutorial.html">tutorial</a>
describes the construction of a simple application example.

The <tt>examples</tt> directory of the <b>pyburg</b> distribution contains several simple examples.
Please consult a compilers textbook for the theory and underlying implementation details of code selection. Engineering a compiler.

</body>
</html>
